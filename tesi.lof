\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces {\itshape A common representation of a neural network: a single node works as the perceptron described before. The network is composed by the input layer, the hidden layers and the output layer. The depth of the network is determined by the number of hidden layers.}}}{6}{figure.1.1}
\contentsline {figure}{\numberline {1.2}{\ignorespaces \itshape Visual example of gradient descent for a model with 2 weights. The idea is to modify the weights to follow the direction of the steepest descent for the landscape of the error function}}{7}{figure.1.2}
\contentsline {figure}{\numberline {1.3}{\ignorespaces \itshape Comparison between a T1-weighted slice (left) and a T2-weighted slice (right) for the same patient}}{13}{figure.1.3}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces \itshape Visual representation of a convolution of an Image $I$ with a kernel of size 3}}{17}{figure.2.1}
\contentsline {figure}{\numberline {2.2}{\ignorespaces \itshape Scheme of the im2col algorithm using a $2 \times 2 \times 3$ filter with stride 1 on a $4 \times 4 \times 3$ image. The matrix multiplication is between a $n \times 12$ and a $12 \times 9$ matrixes.}}{19}{figure.2.2}
\contentsline {figure}{\numberline {2.3}{\ignorespaces \itshape Scheme of maxpool operations with a kernel of size $2 \times 2$ and stride $2$ over an image of size $4 \times 4$. Picture from CS231n}}{21}{figure.2.3}
\contentsline {figure}{\numberline {2.4}{\ignorespaces \itshape Average pooling applied to a test image: (left) the original image, (center) average pooling with a $3 \times 3$ kernel, (right) average pooling with a $30 \times 30$ kernel. The images have been obtained using NumPyNet}}{21}{figure.2.4}
\contentsline {figure}{\numberline {2.5}{\ignorespaces \itshape Max pooling applied to a test image: (left) the original image, (center) max pooling with a $30 \times 3$0 kernel and stride $20$, (right) max pooling errors image. Only few of the pixels are responsible for the error backpropagation. The images have been obtained using NumPyNet}}{23}{figure.2.5}
\contentsline {figure}{\numberline {2.6}{\ignorespaces \itshape Scheme of the shortcut layer as designed by the authors \cite {residual}. The output of the second layer become a linear combination of the input x and its own output.}}{24}{figure.2.6}
\contentsline {figure}{\numberline {2.7}{\ignorespaces \itshape example of deconvolution: (left) a normal convolution with size 3 and stride 1, (right) after applying a "zeros upsampling" the convolution of size 3 and stride 1 become a deconvolution}}{26}{figure.2.7}
\contentsline {figure}{\numberline {2.8}{\ignorespaces \itshape Example of pixel shuffling proposed by the authors \cite {pixelshuffle}. In this example, $r^2$ features maps are re-arranged into a single-channeled high resolution output.}}{26}{figure.2.8}
\contentsline {figure}{\numberline {2.9}{\ignorespaces \itshape Activation functions applied on test image. From top to bottom: Elu, Relu and Logistic.}}{31}{figure.2.9}
\contentsline {figure}{\numberline {2.10}{\ignorespaces \itshape Comparisons between time to perform forward (left) and backward (right) for Convolutional Layer in Byron and Tensorflow on a 4D tensor of size $16 \times 512 \times 512 \times 3$ for size 3, stride 1 and 100 filters.}}{33}{figure.2.10}
\contentsline {figure}{\numberline {2.11}{\ignorespaces \itshape Comparisons between time to perform forward (left) and backward (right) for Convolutional Layer in Byron and Tensorflow on a 4D tensor of size $16 \times 512 \times 512 \times 3$ for size 3, stride 2 and 100 filters.}}{34}{figure.2.11}
\contentsline {figure}{\numberline {2.12}{\ignorespaces \itshape Comparisons between times to perform forward (left) and backward (right) for Maxpool Layer in Byron and Tensorflow on a 4D tensor of size $16 \time 512 \times 512 \times 3$ for size 3 and stride 1.}}{34}{figure.2.12}
\contentsline {figure}{\numberline {2.13}{\ignorespaces \itshape Comparisons between times to perform forward (left) and backward (right) for Maxpool Layer in Byron and Tensorflow on a 4D tensor of size $16 \time 512 \times 512 \times 3$ for size 30 and stride 1.}}{35}{figure.2.13}
\contentsline {figure}{\numberline {2.14}{\ignorespaces \itshape Comparisons between times to perform forward (left) and backward (right) for Shuffler Layer in Byron and Tensorflow on a 4D tensor of size $16 \time 512 \times 512 \times 108$ for scale 6}}{36}{figure.2.14}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces \itshape architecture of the single scale SR Network (EDSR)}}{38}{figure.3.1}
\contentsline {figure}{\numberline {3.2}{\ignorespaces \itshape comparisons between {\ttfamily EDSR} architecture on the left and {\ttfamily WDSR} architecture on the right}}{40}{figure.3.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces \itshape Super Resolution visual example extracted from the DIV2K validation set. The quality score in terms of PSNR and SSIM are compared between a standard bi-cubic up-sampling and the EDSR and WDSR models.}}{41}{figure.3.3}
\contentsline {figure}{\numberline {3.4}{\ignorespaces \itshape Super Resolution visual example extracted from the DIV2K validation set. The quality score in terms of PSNR and SSIM are compared between a standard bi-cubic up-sampling and the EDSR and WDSR models.}}{42}{figure.3.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces \itshape Super Resolution visual example extracted from the DIV2K validation set. The quality score in terms of PSNR and SSIM are compared between a standard bi-cubic up-sampling and the EDSR and WDSR models.}}{42}{figure.3.5}
\contentsline {figure}{\numberline {3.6}{\ignorespaces \itshape HR $256 \times 256$ original image at three different stages of depth: (left) slice 30 where still a lot of information about the brain is hidden, (center) slice 100 which is a central slice where most of the information is stored, (right) slice 150 which starts the less informative area of the brain.}}{43}{figure.3.6}
\contentsline {figure}{\numberline {3.7}{\ignorespaces \itshape $128 \times 128$ LR version of the same slices shown for the HR case.}}{44}{figure.3.7}
\contentsline {figure}{\numberline {3.8}{\ignorespaces \itshape $64 \times 64$ LR version of the same slices shown for the HR case.}}{44}{figure.3.8}
\contentsline {figure}{\numberline {3.9}{\ignorespaces \itshape Three of the 20 rotation angles used as input for Super Resolution models and Bicubic. (left) reference angle of 0 degree, (centre) angle step of 18 degree, (right) large rotation of 108\IeC {\textdegree } respect to the reference. }}{45}{figure.3.9}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces \itshape Average trends of PSNR (left) and SSIM (right) for the three channels (Red, Blue, Green lines) of the Super Resolution EDSR model compared with the bicubic algorithm scores (Yellow) as functions of the slices. The average is performed for every patients and for every rotation, cosidering only T1 weighted NMR. The dotted lines highlights the slices where the bicubic and super-resolution green channel performances intersect.}}{47}{figure.4.1}
\contentsline {figure}{\numberline {4.2}{\ignorespaces \itshape (left) original image, (center) reconstruction performed with {\ttfamily EDSR} blue channel, (right) reconstruction using the bicubic method. The input in this case is not rotated.}}{47}{figure.4.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces \itshape Average trends of PSNR (left) and SSIM (right) for the three channels (Red, Blue, Green lines) of the super-resolution EDSR model compared with the bicubic algorithm scores (Yellow) as functions of the slices. The average is performed for every patients and for every rotation, considering only T2-weighted NMRs. In this case the bicubic seems to perform better, a part from the central section of the slice.}}{48}{figure.4.3}
\contentsline {figure}{\numberline {4.4}{\ignorespaces \itshape (left) original image, (center) reconstruction performed with {\ttfamily EDSR}, (right) reconstruction using the bicubic method for a T2-weighted image. The input in this case is not rotated.}}{48}{figure.4.4}
\contentsline {figure}{\numberline {4.5}{\ignorespaces \itshape Average trends of PSNR (left) and SSIM (right) for the three channels (Red, Blue, Green lines) of the Super Resolution WDSR model compared with the bicubic algorithm scores (Yellow) as functions of the slices. The average is performed for every patients and for every rotation, for T1-weighted NMRs.}}{49}{figure.4.5}
\contentsline {figure}{\numberline {4.6}{\ignorespaces \itshape (left) original image, (center) reconstruction performed with {\ttfamily WDSR}, (right) reconstruction using the bicubic method for a T1-weighted image. The input in this case is not rotated.}}{50}{figure.4.6}
\contentsline {figure}{\numberline {4.7}{\ignorespaces \itshape Average trends of PSNR (left) and SSIM (right) for the three channels (Red, Blue, Green lines) of the Super Resolution WDSR model compared with the bicubic algorithm scores (Yellow) as functions of the slices. The average is performed for every patients and for every rotation, for T2-weighted NMRs.}}{50}{figure.4.7}
\contentsline {figure}{\numberline {4.8}{\ignorespaces \itshape (left) original image, (center) reconstruction performed with {\ttfamily WDSR}, (right) reconstruction using the bicubic method for a T2-weighted image. The input in this case is not rotated.}}{51}{figure.4.8}
\contentsline {figure}{\numberline {4.9}{\ignorespaces \itshape average trends of PSNR (left) and SSIM (right) for {\ttfamily EDSR} x2 and bicubic algorithm as functions of the input angle of rotations.}}{51}{figure.4.9}
\contentsline {figure}{\numberline {4.10}{\ignorespaces \itshape average trends of PSNR (left) and SSIM (right) for {\ttfamily WDSR} x4 and bicubic algorithm as functions of the input angle of rotations.}}{52}{figure.4.10}
\contentsline {figure}{\numberline {4.11}{\ignorespaces \itshape comparison between {\ttfamily EDSR} x2 and bicubic, if compared with the images above, the level of recostruction is really similar to slices without rotations in figure \ref {fig:edsr-upscale}}}{52}{figure.4.11}
\contentsline {figure}{\numberline {4.12}{\ignorespaces \itshape comparison between {\ttfamily WDSR} x4 and bicubic, if compared with the images above, the level of recostruction is better than slices without rotations in figure \ref {wdsr-upscale}. Indeed the number of artifacts seems to be far lower than before for {\ttfamily WDSR}.}}{53}{figure.4.12}
\contentsline {figure}{\numberline {4.13}{\ignorespaces \itshape Absolute differences for {\ttfamily EDSR} reconstruction (left) and bicubic (right), for a T1-weighted image. In both cases, the major differences seems to lies in the scalps of the subjecs. Though, it can be seen that the background is not zero, which means it has an impact on the scores.}}{54}{figure.4.13}
\contentsline {figure}{\numberline {4.14}{\ignorespaces \itshape Histograms of the distribution of differences pixel-by-pixel for the reconstruction performed by EDSR (Blue) and by the bicubic algorithm (Orange), for a T1-weighted NMR. The histogram has been cut between 0.05 and 0.1 on the $y$ axis to better represent the lower parts.}}{55}{figure.4.14}
\contentsline {figure}{\numberline {4.15}{\ignorespaces \itshape Absolute differences of Super resolved image obtained with {\ttfamily EDSR} (left) and bicubic (right) for T2-weighted NMR. This time the major differences seem to be mostly located on the inner parts of the sample, in particular around edges.}}{56}{figure.4.15}
\contentsline {figure}{\numberline {4.16}{\ignorespaces \itshape Histograms of the distribution of differences pixel-by-pixel for a reconstruction performed by EDSR (Blue) and by the bicubic algorithm (Orange), for a T2-weighted NMR. The histogram has been cut between 0.08 and 0.1 on the $y$ axis to better represent the lower parts.}}{56}{figure.4.16}
\contentsline {figure}{\numberline {4.17}{\ignorespaces \itshape Absolute differences of Super resolved images obtained with {\ttfamily WDSR} (left) and bicubic (right) for a T1-weighted NMR. Also in this case the major differences seems to be focused on the scalp of the subjects.}}{57}{figure.4.17}
\contentsline {figure}{\numberline {4.18}{\ignorespaces \itshape Histograms of the distribution of differences pixel-by-pixel for a reconstruction performed by EDSR (Blue) and by the bicubic algorithm (Orange), for a T2-weighted NMR. The histogram has been cut between 0.08 and 0.1 on the $y$ axis to better represent the lower parts.}}{58}{figure.4.18}
\contentsline {figure}{\numberline {4.19}{\ignorespaces \itshape Absolute differences of Super resolved images obtained with {\ttfamily WDSR} (left) and bicubic (right) for a T2-weighted NMR.}}{58}{figure.4.19}
\contentsline {figure}{\numberline {4.20}{\ignorespaces \itshape Histograms of the distribution of differences pixel-by-pixel for a reconstruction performed by EDSR (Blue) and by the bicubic algorithm (Orange), for a T2-weighted NMR. The histogram has been cut between 0.08 and 0.1 on the $y$ axis to better represent the lower parts.}}{59}{figure.4.20}
\contentsline {figure}{\numberline {4.21}{\ignorespaces \itshape Example of application of a mask on one of the slices of the original 3D map. (left) Original image, (center) Mask obtained from FSL BET and (right) Mask applyed to the original image. }}{60}{figure.4.21}
\contentsline {figure}{\numberline {4.22}{\ignorespaces \itshape Examples of Brain Extraction for original image (left), EDSR image (center) and Bicubic results (right). The binary masks are different for the three images.}}{60}{figure.4.22}
\contentsline {figure}{\numberline {4.23}{\ignorespaces \itshape Absolute differences for Super Resolution (EDSR, left) and bicubic (right). The images are obtained by computing a pixel-wise absolute difference with the original slice. We can see the main dissimilarities on the border of the two images, meaning that the BET didn't catch all the relevant informations on the reconstructed images.}}{61}{figure.4.23}
\contentsline {figure}{\numberline {4.24}{\ignorespaces \itshape Absolute differences for Super Resolution {\ttfamily WDSR}, left) and bicubic (right). In this case, the principal dissimilarities are not focused only on the outer parts of the brain and that is understandable, given the high level of downsampling.}}{61}{figure.4.24}
\contentsline {figure}{\numberline {4.25}{\ignorespaces \itshape Histogram of differences for an image obtained with x2 up-sampling and after Brain Extraction. The background componenent is completely shifted towards zero, while the Brain componentent spreaded and shifted toward higher intensity for contrast manipulation. The distributions for the two methods are nearly identical. The histogram has been cut on the y axis between 0.07 and 0.2 to better represent the Brain Component}}{62}{figure.4.25}
\contentsline {figure}{\numberline {4.26}{\ignorespaces \itshape Trends of IoU scores for the different upsamplig methods. (left) comparison between the mask obtained from {\ttfamily EDSR} and bicubic recostructions and (right) same graph for {\ttfamily WDSR} and bicubic. Notice that some slices are cut from comparisons since they are black images and both intersection and union are 0.}}{63}{figure.4.26}
\contentsline {figure}{\numberline {4.27}{\ignorespaces \itshape Average trends of PSNR (left) and SSIM (right) for the three channels (Red, Blue, Green lines) of the Super Resolution {\ttfamily EDSR} model compared with the bicubic algorithm scores (Yellow) as functions of the slices. Above are the results pre brain extraction while below the ones post brain extraction. The average is performed for one patient and for every rotation, for T1-weighted NMRs.}}{64}{figure.4.27}
\contentsline {figure}{\numberline {4.28}{\ignorespaces \itshape Average trends of PSNR (left) and SSIM (right) for the three channels (Red, Blue, Green lines) of the Super Resolution {\ttfamily WDSR} model compared with the bicubic algorithm scores (Yellow) as functions of the slices. Above are the results pre brain extraction while below the ones post brain extraction. The average is performed for one patient and for every rotation, for T1-weighted NMRs.}}{65}{figure.4.28}
\addvspace {10\p@ }
